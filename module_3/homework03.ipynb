{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f700b2",
   "metadata": {},
   "source": [
    "# Homework03 - Rui Pinto"
   ]
  },
  {
   "cell_type": "code",
   "id": "90fbd84d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:24:24.925223Z",
     "start_time": "2025-07-15T09:24:24.920579Z"
    }
   },
   "source": [
    "# before running from project root: mlflow ui --backend-store-uri file:$(pwd)/03-orchestration/mlruns\n",
    "# OR if running from 03-orchestration directory: mlflow ui --backend-store-uri file:./mlruns"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ce2271d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:24:28.683457Z",
     "start_time": "2025-07-15T09:24:25.177964Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Import utility functions that we've defined for model training and MLflow logging\n",
    "from module_3.src.model_utils import (\n",
    "    read_dataframe,\n",
    "    create_X,\n",
    "    train_linear_model,\n",
    "    log_model_with_mlflow,\n",
    "    find_model_size,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not connect to MLflow server at http://localhost:5000: API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''\n",
      "Using local directory for MLflow tracking\n",
      "Using local MLflow directory: ../../mlruns\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b3cbbc8a",
   "metadata": {},
   "source": [
    "# Q1. Select the Tool\n",
    "\n",
    "You can use the same tool you used when completing the module, or choose a different one for your homework.\n",
    "\n",
    "What's the name of the orchestrator you chose?\n",
    "\n",
    "- Prefect ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79c17e",
   "metadata": {},
   "source": [
    "# Q2. Version\n",
    "\n",
    "What's the version of the orchestrator?"
   ]
  },
  {
   "cell_type": "code",
   "id": "590b82bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:24:29.002559Z",
     "start_time": "2025-07-15T09:24:28.812942Z"
    }
   },
   "source": [
    "# check version of prefect\n",
    "print(\"Checking Prefect version...\")\n",
    "\n",
    "\n",
    "def get_prefect_version():\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"prefect\", \"--version\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error checking Prefect version: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "version = get_prefect_version()\n",
    "if version:\n",
    "    print(f\"Prefect version: {version}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Prefect version...\n",
      "Error checking Prefect version: Command '['/opt/homebrew/Caskroom/miniforge/base/envs/mlops_zoomcamp/bin/python', '-m', 'prefect', '--version']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "09cb92bd",
   "metadata": {},
   "source": [
    "# Q3. Creating a pipeline\n",
    "\n",
    "Let's read the March 2023 Yellow taxi trips data.\n",
    "\n",
    "How many records did we load?\n",
    "\n",
    "- 3,003,766\n",
    "- 3,203,766\n",
    "- 3,403,766 ✅\n",
    "- 3,603,766\n",
    "\n",
    "(Include a print statement in your code)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5a29a93e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:24:29.088068Z",
     "start_time": "2025-07-15T09:24:29.065378Z"
    }
   },
   "source": [
    "#!curl https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet > data/yellow_tripdata_2023-03.parquet"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3135dea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:24:30.219004Z",
     "start_time": "2025-07-15T09:24:29.129799Z"
    }
   },
   "source": [
    "def read_parquet_file(file_path):\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        print(f\"DataFrame shape: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading parquet file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Using our read_dataframe function directly\n",
    "file_path = \"../data/yellow_tripdata_2023-03.parquet\"\n",
    "\n",
    "# Option 1: Load using direct parquet file path\n",
    "try:\n",
    "    raw_df = pd.read_parquet(file_path)\n",
    "    print(f\"DataFrame shape: {raw_df.shape}\")\n",
    "    print(f\"\\nWe have {raw_df.shape[0]:,} records\")\n",
    "    print(\"DataFrame loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading parquet file: {e}\")\n",
    "    print(\"Trying to load through read_dataframe function...\")\n",
    "    # Option 2: If direct loading fails, use our function\n",
    "    raw_df = read_dataframe(2023, filename=file_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (3403766, 19)\n",
      "\n",
      "We have 3,403,766 records\n",
      "DataFrame loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7af4ccc0",
   "metadata": {},
   "source": [
    "# Q4. Data preparation\n",
    "\n",
    "Let's continue with pipeline creation.\n",
    "\n",
    "We will use the same logic for preparing the data we used previously.\n",
    "\n",
    "This is what we used (adjusted for yellow dataset):\n",
    "\n",
    "```bash\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "Let's apply to the data we loaded in question 3.\n",
    "\n",
    "What's the size of the result?\n",
    "\n",
    "- 2,903,766\n",
    "- 3,103,766\n",
    "- 3,316,216 ✅\n",
    "- 3,503,766"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e4718b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:24:53.780448Z",
     "start_time": "2025-07-15T09:24:30.286061Z"
    }
   },
   "source": [
    "# Process the data using read_dataframe function\n",
    "df = read_dataframe(2023, 3)\n",
    "print(f\"\\nNumber of records after data preparation: {df.shape[0]:,}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read from local file: data/yellow_tripdata_2023-03.parquet\n",
      "Local file not found. Attempting to download from URL.\n",
      "DataFrame shape after processing: (3316216, 20)\n",
      "\n",
      "Number of records after data preparation: 3,316,216\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "a98ff548",
   "metadata": {},
   "source": [
    "# Question 5. Train a model\n",
    "\n",
    "We will now train a linear regression model using the same code as in homework 1.\n",
    "\n",
    "- Fit a dict vectorizer.\n",
    "- Train a linear regression with default parameters.\n",
    "- Use pick up and drop off locations separately, don't create a combination feature.\n",
    "\n",
    "Let's now use it in the pipeline. We will need to create another transformation block, and return both the dict vectorizer and the model.\n",
    "\n",
    "What's the intercept of the model?\n",
    "\n",
    "Hint: print the intercept_ field in the code block\n",
    "\n",
    "- 21.77\n",
    "- 24.77 ✅\n",
    "- 27.77\n",
    "- 31.77"
   ]
  },
  {
   "cell_type": "code",
   "id": "1993c62f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:25:58.886634Z",
     "start_time": "2025-07-15T09:24:53.890948Z"
    }
   },
   "source": [
    "# fit dict vectorizer and transform the data\n",
    "X, dv = create_X(df)\n",
    "\n",
    "# prepare target variable\n",
    "target = \"duration\"\n",
    "y = df[target].values\n",
    "\n",
    "# Train model using our utility function\n",
    "lr, rmse = train_linear_model(X, y)\n",
    "\n",
    "# print the intercept\n",
    "print(f\"Model intercept: {lr.intercept_:.2f}\")\n",
    "print(f\"RMSE on training data: {rmse:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model intercept: 24.78\n",
      "RMSE on training data: 8.16\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "1e30bc1a",
   "metadata": {},
   "source": [
    "# Q6 Register the model \n",
    "\n",
    "The model is trained, so let's save it with MLFlow.\n",
    "\n",
    "Find the logged model, and find MLModel file. What's the size of the model? (`model_size_bytes` field):\n",
    "\n",
    "- 14,534\n",
    "- 9,534\n",
    "- 4,534 ✅\n",
    "- 1,534"
   ]
  },
  {
   "cell_type": "code",
   "id": "dca9b4f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:26:04.552171Z",
     "start_time": "2025-07-15T09:25:58.979428Z"
    }
   },
   "source": [
    "# Register the model with MLflow\n",
    "run_id, artifact_uri = log_model_with_mlflow(lr, X, y, dv, rmse)\n",
    "\n",
    "# Print the run_id and artifact_uri\n",
    "print(f\"MLflow run ID: {run_id}\")\n",
    "print(f\"Artifact URI: {artifact_uri}\")\n",
    "\n",
    "# Find model size bytes in MLmodel file\n",
    "model_sizes = find_model_size()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/15 11:25:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001B[31m2025/07/15 11:26:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow run ID: 443a033e12054e3eba3f13cdc7b28149\n",
      "Artifact URI: file:///Users/jordanharris/Code/mlops_zoomcamp/module_3/../../mlruns/220095353492611871/443a033e12054e3eba3f13cdc7b28149/artifacts\n",
      "Found 2 MLmodel files\n",
      "\n",
      "File: ../../mlruns/220095353492611871/models/m-b3ae76ac18b94d169bb80acd00903c29/artifacts/MLmodel\n",
      "Model size: 4516 bytes\n",
      "\n",
      "File: ../../mlruns/220095353492611871/models/m-c9e0a328ffe84a20ae71c9c16bcc5c8a/artifacts/MLmodel\n",
      "Model size: 4516 bytes\n",
      "\n",
      "Q6 Answer: 4,534 bytes\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
